{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datasets import Dataset\n",
    "import evaluate\n",
    "from transformers import RobertaForSequenceClassification, RobertaTokenizerFast\n",
    "from transformers import TrainingArguments, Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>I miss you  I wish it was the 18th already!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>i think i'm confused and worried - need a strong coffee and a smoke! will venture back to twitterverse later - is it all my fault? OMG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>unfortunately no shoot today, my friend is busy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>is going to work. I dont feel very well today.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>My phone was dying and it beeped at 4 am. Couldn't get back to sleep. This sucks</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19995</th>\n",
       "      <td>1</td>\n",
       "      <td>It's the little things in life which makes it so enjoyable</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19996</th>\n",
       "      <td>1</td>\n",
       "      <td>girlllllllllls just wanna have fun!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19997</th>\n",
       "      <td>1</td>\n",
       "      <td>I wish that was true we shall do it later</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19998</th>\n",
       "      <td>1</td>\n",
       "      <td>- soo beautiful  demi returns to Chile!! we love you</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19999</th>\n",
       "      <td>1</td>\n",
       "      <td>it was so beautiful out today, I didn't mind the traffic.  plus I had just scored a new blanket for nothing!</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       label  \\\n",
       "0          0   \n",
       "1          0   \n",
       "2          0   \n",
       "3          0   \n",
       "4          0   \n",
       "...      ...   \n",
       "19995      1   \n",
       "19996      1   \n",
       "19997      1   \n",
       "19998      1   \n",
       "19999      1   \n",
       "\n",
       "                                                                                                                                          text  \n",
       "0                                                                                                  I miss you  I wish it was the 18th already!  \n",
       "1      i think i'm confused and worried - need a strong coffee and a smoke! will venture back to twitterverse later - is it all my fault? OMG   \n",
       "2                                                                                             unfortunately no shoot today, my friend is busy   \n",
       "3                                                                                              is going to work. I dont feel very well today.   \n",
       "4                                                            My phone was dying and it beeped at 4 am. Couldn't get back to sleep. This sucks   \n",
       "...                                                                                                                                        ...  \n",
       "19995                                                                              It's the little things in life which makes it so enjoyable   \n",
       "19996                                                                                                     girlllllllllls just wanna have fun!   \n",
       "19997                                                                                               I wish that was true we shall do it later   \n",
       "19998                                                                                    - soo beautiful  demi returns to Chile!! we love you   \n",
       "19999                             it was so beautiful out today, I didn't mind the traffic.  plus I had just scored a new blanket for nothing!  \n",
       "\n",
       "[20000 rows x 2 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.set_option('display.max_colwidth', None)\n",
    "\n",
    "df = pd.read_csv('../Data/Twitter/cleaned_data.csv', encoding='latin')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 20000 entries, 0 to 19999\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   label   20000 non-null  int64 \n",
      " 1   text    20000 non-null  object\n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 312.6+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>I miss you  I wish it was the 18th already!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>i think i'm confused and worried - need a strong coffee and a smoke! will venture back to twitterverse later - is it all my fault? OMG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>unfortunately no shoot today, my friend is busy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>is going to work. I dont feel very well today.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>My phone was dying and it beeped at 4 am. Couldn't get back to sleep. This sucks</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19995</th>\n",
       "      <td>1</td>\n",
       "      <td>It's the little things in life which makes it so enjoyable</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19996</th>\n",
       "      <td>1</td>\n",
       "      <td>girlllllllllls just wanna have fun!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19997</th>\n",
       "      <td>1</td>\n",
       "      <td>I wish that was true we shall do it later</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19998</th>\n",
       "      <td>1</td>\n",
       "      <td>- soo beautiful  demi returns to Chile!! we love you</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19999</th>\n",
       "      <td>1</td>\n",
       "      <td>it was so beautiful out today, I didn't mind the traffic.  plus I had just scored a new blanket for nothing!</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       label  \\\n",
       "0          0   \n",
       "1          0   \n",
       "2          0   \n",
       "3          0   \n",
       "4          0   \n",
       "...      ...   \n",
       "19995      1   \n",
       "19996      1   \n",
       "19997      1   \n",
       "19998      1   \n",
       "19999      1   \n",
       "\n",
       "                                                                                                                                          text  \n",
       "0                                                                                                  I miss you  I wish it was the 18th already!  \n",
       "1      i think i'm confused and worried - need a strong coffee and a smoke! will venture back to twitterverse later - is it all my fault? OMG   \n",
       "2                                                                                             unfortunately no shoot today, my friend is busy   \n",
       "3                                                                                              is going to work. I dont feel very well today.   \n",
       "4                                                            My phone was dying and it beeped at 4 am. Couldn't get back to sleep. This sucks   \n",
       "...                                                                                                                                        ...  \n",
       "19995                                                                              It's the little things in life which makes it so enjoyable   \n",
       "19996                                                                                                     girlllllllllls just wanna have fun!   \n",
       "19997                                                                                               I wish that was true we shall do it later   \n",
       "19998                                                                                    - soo beautiful  demi returns to Chile!! we love you   \n",
       "19999                             it was so beautiful out today, I didn't mind the traffic.  plus I had just scored a new blanket for nothing!  \n",
       "\n",
       "[20000 rows x 2 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'label': 0, 'text': ' I miss you  I wish it was the 18th already!'}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MODEL = \"roberta-base\"\n",
    "tokenizer = RobertaTokenizerFast.from_pretrained('roberta-base')\n",
    "\n",
    "\n",
    "def tokenize_function(examples):\n",
    "    return tokenizer(examples[\"text\"], padding=\"max_length\", truncation=True)\n",
    "\n",
    "dataset = Dataset.from_pandas(df)\n",
    "dataset[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "39afad1cd4a64e8ca1b7cd95cb2ad906",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/20000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenized_datasets = dataset.map(tokenize_function, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9e772a12019b4d0d9e4252d2ed39bb2e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Stringifying the column:   0%|          | 0/20000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "40d379f7228c49b092017a5287232642",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Casting to class labels:   0%|          | 0/20000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['label', 'text', 'input_ids', 'attention_mask'],\n",
       "        num_rows: 18000\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['label', 'text', 'input_ids', 'attention_mask'],\n",
       "        num_rows: 2000\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_datasets = tokenized_datasets.class_encode_column('label')\n",
    "tokenized_datasets = tokenized_datasets.train_test_split(test_size=0.5, stratify_by_column='label')\n",
    "tokenized_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = tokenized_datasets[\"train\"].select(range(5000))\n",
    "eval_dataset = tokenized_datasets[\"train\"].select(range(5000,7000))\n",
    "test_dataset = tokenized_datasets[\"test\"].select(range(10000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at roberta-base were not used when initializing RobertaForSequenceClassification: ['lm_head.layer_norm.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.weight', 'lm_head.dense.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.weight', 'classifier.out_proj.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "c:\\Users\\cjlongoria\\Documents\\College\\CS522\\Project\\.venv\\lib\\site-packages\\transformers\\optimization.py:391: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "19cf0c399d5f466091862fe6915c7204",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3125 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.6908, 'learning_rate': 8.399999999999999e-07, 'epoch': 0.8}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7dfa4a241b6544959a98d181d24c828e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/250 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.6591541767120361, 'eval_accuracy': 0.763, 'eval_f1': 0.7683284457478006, 'eval_precision': 0.7751479289940828, 'eval_recall': 0.7616279069767442, 'eval_runtime': 22.7888, 'eval_samples_per_second': 87.762, 'eval_steps_per_second': 10.97, 'epoch': 1.0}\n",
      "{'loss': 0.5742, 'learning_rate': 6.800000000000001e-07, 'epoch': 1.6}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c29be3f3e899410eb373392aa1e43a8d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/250 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.43135279417037964, 'eval_accuracy': 0.8085, 'eval_f1': 0.8147073052733431, 'eval_precision': 0.8135265700483092, 'eval_recall': 0.8158914728682171, 'eval_runtime': 22.2473, 'eval_samples_per_second': 89.899, 'eval_steps_per_second': 11.237, 'epoch': 2.0}\n",
      "{'loss': 0.4587, 'learning_rate': 5.2e-07, 'epoch': 2.4}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6db863bfd6174ea09919dadaf5eda707",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/250 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.4265088140964508, 'eval_accuracy': 0.816, 'eval_f1': 0.8247619047619048, 'eval_precision': 0.8108614232209738, 'eval_recall': 0.8391472868217055, 'eval_runtime': 22.3136, 'eval_samples_per_second': 89.631, 'eval_steps_per_second': 11.204, 'epoch': 3.0}\n",
      "{'loss': 0.4392, 'learning_rate': 3.6e-07, 'epoch': 3.2}\n",
      "{'loss': 0.4321, 'learning_rate': 2e-07, 'epoch': 4.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f4ce71f7d8d640a0867ec4d0622cbcf4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/250 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.4245370626449585, 'eval_accuracy': 0.8165, 'eval_f1': 0.8194786030496803, 'eval_precision': 0.8321678321678322, 'eval_recall': 0.8071705426356589, 'eval_runtime': 22.4482, 'eval_samples_per_second': 89.094, 'eval_steps_per_second': 11.137, 'epoch': 4.0}\n",
      "{'loss': 0.4031, 'learning_rate': 4e-08, 'epoch': 4.8}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6b6b2366c8594ba6844f38b5222567bd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/250 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.42253461480140686, 'eval_accuracy': 0.82, 'eval_f1': 0.8264223722275795, 'eval_precision': 0.8224568138195777, 'eval_recall': 0.8304263565891473, 'eval_runtime': 22.6222, 'eval_samples_per_second': 88.409, 'eval_steps_per_second': 11.051, 'epoch': 5.0}\n",
      "{'train_runtime': 950.614, 'train_samples_per_second': 26.299, 'train_steps_per_second': 3.287, 'train_loss': 0.4979331640625, 'epoch': 5.0}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=3125, training_loss=0.4979331640625, metrics={'train_runtime': 950.614, 'train_samples_per_second': 26.299, 'train_steps_per_second': 3.287, 'train_loss': 0.4979331640625, 'epoch': 5.0})"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = RobertaForSequenceClassification.from_pretrained(\"roberta-base\", num_labels=2)\n",
    "metric = evaluate.combine([\"accuracy\", \"f1\", \"precision\", \"recall\"])\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    predictions = np.argmax(logits, axis=-1)\n",
    "    return metric.compute(predictions=predictions, references=labels)\n",
    "\n",
    "training_args = TrainingArguments(output_dir=\"test_trainer\", evaluation_strategy=\"epoch\", learning_rate=.000001, num_train_epochs=5)\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=eval_dataset,\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e2526684144e44569ec5d133b28a04aa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/250 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.3960396349430084,\n",
       " 'eval_accuracy': 0.836,\n",
       " 'eval_f1': 0.8390578999018645,\n",
       " 'eval_precision': 0.8236994219653179,\n",
       " 'eval_recall': 0.855,\n",
       " 'eval_runtime': 19.9562,\n",
       " 'eval_samples_per_second': 100.219,\n",
       " 'eval_steps_per_second': 12.527,\n",
       " 'epoch': 5.0}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.evaluate(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
